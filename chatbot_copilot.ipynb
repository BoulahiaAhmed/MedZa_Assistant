{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSGUi3a8a5rB"
      },
      "source": [
        "# **Chatbot copilot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXhjOieocqf4",
        "outputId": "638dfa75-b55f-4ce1-dcd5-0c71011fe250"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DM5LdLQbZ1p",
        "outputId": "9fd69168-1cab-41e1-8949-8939abac3f5d"
      },
      "outputs": [],
      "source": [
        "!pip -q install duckduckgo-search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJY_WLLNbES2"
      },
      "source": [
        "## Data retriever using DuckDuckgo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXpglOv7log7"
      },
      "source": [
        "### DuckDuckGo with Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-nc9_Nefce7A"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import DuckDuckGoSearchRun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rrTdAAsWbZ7A"
      },
      "outputs": [],
      "source": [
        "search = DuckDuckGoSearchRun()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "GNTDS2kVcbbb",
        "outputId": "ac6fbf49-1292-46e8-ca61-8b9021f689fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Learn how to operationalize and manage large language models using Azure ML, a MLOps platform that enables the automation of tasks such as data preparation, model discovery, tuning, deployment, and monitoring. Explore the benefits and challenges of using LLMs in real-world applications and the risks of using them responsibly. LLMOps is a process of managing Large Language Models (LLMs) and LLM-powered applications using tools and best practices. It differs from MLOps in terms of tools, methods, and goals. Learn how LLMOps facilitates the development, deployment, and maintenance of LLMs using prompt engineering, fine-tuning, RAG, and more. Learn what LLMOps is, how it works, and why it is important for the deployment and maintenance of large language models (LLMs). Find out the steps, techniques, and challenges of LLMOps, such as selection of foundation models, adaptation to downstream tasks, evaluation, and deployment and monitoring. Compare LLMOps with MLOps and see examples of popular LLMs. Learn how to develop, test, optimize, and deploy large language operations (LLMOps) using prompt flow and GitHub. This article provides a template and guidance for LLMOps with prompt flow, a streamlined and structured process for building LLM-infused applications. It covers the features, stages, process, and prerequisites of LLMOps with prompt flow. Learn what LLMOps (Large Language Model Operations) are and how they differ from MLOps (Machine Learning Operations). Discover the essential components of LLMOps, such as data management, prompt engineering, human feedback loop, and vector databases. Explore the challenges and best practices of LLMOps, such as computational resources, ethical concerns, transfer learning, and deployment scaling.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search.run(\"llmops\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ggJJDEuDdOhu"
      },
      "outputs": [],
      "source": [
        "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
        "from langchain.tools import DuckDuckGoSearchResults\n",
        "\n",
        "wrapper = DuckDuckGoSearchAPIWrapper(region=\"de-de\", time=\"d\", max_results=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ft-cE_Qdcbi4"
      },
      "outputs": [],
      "source": [
        "search = DuckDuckGoSearchResults(api_wrapper=wrapper, source=\"news\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "9NZ2wQXhcblT",
        "outputId": "fe75b3a1-8708-4641-cfdb-ab6b11f7ccbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"[snippet: Automated Testing for LLMOps. Learn how LLM-based testing differs from traditional software testing and implement rules-based testing to assess your LLM application. Build model-graded evaluations to test your LLM application using an evaluation LLM. Automate your evals (rules-based and model-graded) using continuous integration tools from ..., title: Automated Testing for LLMOps 03：Comprehensive Testing Framework ..., link: https://blog.csdn.net/shizheng_Li/article/details/136271559], [snippet: All CI/CD pipelines in CircleCI are defined in a single YAML file at the path .circleci/config.yml in your project's Git repository. This tutorial explains the example configuration file used throughout the course. There are three key components to every CircleCI config file: jobs, commands, and workflows., title: Automated Testing for LLMOps 04：Exploring the CircleCI config file, link: https://blog.csdn.net/shizheng_Li/article/details/136271640], [snippet: 为了帮助每一个程序员掌握以上 AI 大模型开发的12项技能，我们准备了一系列免费干货，覆盖以上大模型架构内核、Fine-tuning 微调、RAG、LangChain 开发框架、缓存、Agent 开发、向量数据库、LLMOps 部署治理等12项核心技术，喜欢可以加入我们获取。, title: Llm 大模型技术知识最佳学习路径图发布!-csdn博客, link: https://blog.csdn.net/2201_75499313/article/details/136269586], [snippet: 向量作为数学表示，在LLMs中扮演着将文本数据转换为机器可理解形式的角色；Tokens作为语言单位，是处理和组织文本信息的基本单元；而嵌入则在向量的基础上融入了深层语义信息，使得LLMs能够更加准确地理解和处理语言数据。. 通过理解这些基本概念，我们 ..., title: LLMs的基本组成：向量、Tokens和嵌入_腾讯新闻, link: https://new.qq.com/rain/a/20240224A05WVN00]\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search.run(\"llmops\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UecIV4etl6do"
      },
      "source": [
        "### DuckDuckGo API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from duckduckgo_search import DDGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "22l2SXGkcbgc"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "  \"title\": result[\"title\"],\n",
        "  \"body\": result[\"body\"],\n",
        "  \"link\": result[\"href\"],\n",
        "'''\n",
        "\n",
        "with DDGS() as ddgs:\n",
        "    results = [r for r in ddgs.text('what is llmops?', safesearch='on', timelimit='y', max_results=3)]\n",
        "\n",
        "number_of_result = 0\n",
        "snippets = []\n",
        "\n",
        "for result in results:\n",
        "  number_of_result +=1\n",
        "  title = result['title']\n",
        "  body = result['body']\n",
        "  link = result['href']\n",
        "\n",
        "  snippet = {'title': title, 'body': body, 'link': link}\n",
        "\n",
        "  snippets.append(snippet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ipyct_fdOY8",
        "outputId": "f08db9cc-ecaf-4c11-dead-ade46e7041c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Leverage MLOps for Large Language Models, i.e., LLMOps: Over the years, MLOps has demonstrated its ability to enhance the development, deployment, and maintenance of ML models, leading to more agile and efficient machine learning systems.\n"
          ]
        }
      ],
      "source": [
        "print(snippets[0]['body'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNR6Gxzjs95Z"
      },
      "source": [
        "**Wrap it in a function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zLlKzdYmdOdT"
      },
      "outputs": [],
      "source": [
        "def DDGS_RAG (query, max_results=2):\n",
        "  with DDGS() as ddgs:\n",
        "    results = [r for r in ddgs.text(query, safesearch='on', timelimit='y', max_results=max_results)]\n",
        "\n",
        "  snippets = []\n",
        "  for result in results:\n",
        "    title = result['title']\n",
        "    body = result['body']\n",
        "    link = result['href']\n",
        "    snippet = {'title': title, 'body': body, 'link': link}\n",
        "    snippets.append(snippet)\n",
        "\n",
        "  return snippets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "KLwMdPnflYyN"
      },
      "outputs": [],
      "source": [
        "res = DDGS_RAG('what is python ?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLJdh23FsHKw",
        "outputId": "251f6d6a-bb58-4950-88f5-d865a460e085"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'title': \"What Is Python Used For? A Beginner's Guide | Coursera\",\n",
              "  'body': \"Python is a computer programming language often used to build websites and software, automate tasks, and conduct data analysis. Python is a general-purpose language, meaning it can be used to create a variety of different programs and isn't specialized for any specific problems.\",\n",
              "  'link': 'https://www.coursera.org/articles/what-is-python-used-for-a-beginners-guide-to-using-python'},\n",
              " {'title': 'What is Python? - GeeksforGeeks',\n",
              "  'body': 'Python is a high-level, general-purpose, and interpreted programming language used in various sectors including machine learning, artificial intelligence, data analysis, web development, and many more. Python is known for its ease of use, powerful standard library, and dynamic semantics.',\n",
              "  'link': 'https://www.geeksforgeeks.org/what-is-python/'}]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7BkjyJebEX3"
      },
      "source": [
        "## Chatbot using Google Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4DtNfWhBxBkx"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "u8MQtZuaxhB0"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "tFbc7Vtiw4FZ"
      },
      "outputs": [],
      "source": [
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-pro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "B-PHTX8PxtsP"
      },
      "outputs": [],
      "source": [
        "result = model.generate_content('what is llmops?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH4UpCpGz010",
        "outputId": "5f715f4e-9c67-443e-8c93-2c8a45c19ad4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLMOPS stands for **Lost Laboratory of Kwalish**. It is a tabletop role-playing game adventure module published by Wizards of the Coast in 2014. It is designed for use with the fifth edition of the Dungeons & Dragons role-playing game.\n",
            "\n",
            "The adventure is set in the Forgotten Realms campaign setting and is designed for a party of four to six characters of levels 1-3. The players take on the role of adventurers who are tasked with finding a lost laboratory that belongs to the wizard Kwalish. The laboratory is said to contain powerful magical artifacts and secrets that could be used for good or evil.\n",
            "\n",
            "The adventure is divided into three parts. In the first part, the players must travel to the town of Parnast and gather information about the laboratory. In the second part, the players must travel to the laboratory and explore it. In the third part, the players must defeat the evil forces that are guarding the laboratory and retrieve the magical artifacts.\n",
            "\n",
            "LLMOPS is a well-written and exciting adventure that is perfect for new and experienced D&D players alike. It is a great way to learn the basics of the game and to experience the excitement of exploring a lost dungeon.\n",
            "\n",
            "Here are some of the features of LLMOPS:\n",
            "\n",
            "* A well-developed story that keeps players engaged from start to finish.\n",
            "* A variety of interesting and challenging encounters.\n",
            "* A detailed and atmospheric setting.\n",
            "* A variety of magical artifacts and treasures to discover.\n",
            "* A memorable cast of characters.\n",
            "\n",
            "Overall, LLMOPS is an excellent adventure module that is sure to provide hours of enjoyment for D&D players of all levels.\n"
          ]
        }
      ],
      "source": [
        "print(result.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIsqxmxD0OAC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "Z2bxXAmJw4MN"
      },
      "outputs": [],
      "source": [
        "def Gemini_generation(request, context):\n",
        "  prompt = f\"\"\"Your main task is to respond to the request using the context provided.\n",
        "  The context is indicated with the tag 'context' and the request is indicated with\n",
        "  the tag 'request'.\n",
        "  If the context doesn't have relevant information about the request, or if\n",
        "  the request is a basic and very simple one, you can then respond using your own\n",
        "  knowledge.\n",
        "  Here's some examples of a basic request: 'hello', 'whats 1+1?', 'who are you?'\n",
        "  If the knowledge you have contradicts the context provided. Then use the context\n",
        "  information.\n",
        "\n",
        "  Context:{context}\n",
        "  Request:{request}\n",
        "  \"\"\"\n",
        "  response = model.generate_content(prompt,\n",
        "                                    generation_config=genai.types.GenerationConfig(\n",
        "                                    candidate_count=1,\n",
        "                                    max_output_tokens=500,\n",
        "                                    temperature=0.1))\n",
        "  return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "KvG_ZX2gAlzf"
      },
      "outputs": [],
      "source": [
        "def Gemini_digest (list_of_context, list_of_titles):\n",
        "  prompt = f\"\"\" Your task is to generate a text summary based on the provided data.\n",
        "  To complete this task successfully you need to follow these steps:\n",
        "\n",
        "  1- Generate seperate summaries for each text in the provided list indicated with the tag 'list_of_context'.\n",
        "  2- Understand the context of each summary and generate seperate summaries.\n",
        "  3- The final summary must be in bullet points, add a title for each bulet point, titles must be from the provided list indicated with the tag 'list_of_titles'.\n",
        "  4- Generate a good title for this complete and unified summary.\n",
        "\n",
        "  make sure the output is clear and easy to read.\n",
        "\n",
        "  list_of_context: {list_of_context}.\n",
        "  list_of_titles: {list_of_titles}.\n",
        "  \"\"\"\n",
        "  response = model.generate_content(prompt,\n",
        "                                    generation_config=genai.types.GenerationConfig(\n",
        "                                    candidate_count=1,\n",
        "                                    max_output_tokens=500,\n",
        "                                    temperature=0.2))\n",
        "  return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "DgYwpOWWw4O-"
      },
      "outputs": [],
      "source": [
        "def Chatbot (query):\n",
        "  # Call DDGS_RAG function to retrieve the data\n",
        "  source_data = DDGS_RAG(query)\n",
        "  answers=[]\n",
        "  links=[]\n",
        "  titles=[]\n",
        "  ref=[]\n",
        "\n",
        "  # Loop on the retrieved data and generate responses with Gemini_generation function\n",
        "  for data in source_data:\n",
        "    response = Gemini_generation(query, data['body'])\n",
        "    answers.append(response.text)\n",
        "    links.append(data['link'])\n",
        "    titles.append(data['title'])\n",
        "\n",
        "  # Reference creation (titles, link)\n",
        "  for i in range(len(links)):\n",
        "    ref.append(titles[i]+' :\\n'+links[i])\n",
        "\n",
        "\n",
        "  # Call the Gemini_digest function to return the final answer\n",
        "  summary = Gemini_digest (answers, titles)\n",
        "\n",
        "  digest = summary.text + '\\n\\n'+'References: \\n\\n' + \"\\n\".join(ref)\n",
        "  return digest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "H2K1dnmuT-VS",
        "outputId": "c88af313-b116-4016-c418-ecfe08591d70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title: Understanding LLMOps: Operationalizing and Managing Large Language Models\n",
            "\n",
            "* **LLMOps Overview:**\n",
            "    * LLMOps (Large Language Model Operations) is a specialized branch of MLOps focused on the unique challenges of developing, deploying, and maintaining large language models (LLMs).\n",
            "    * LLMs are AI models trained on massive text data and can perform various language-related tasks, such as text generation, translation, summarization, and question answering.\n",
            "\n",
            "* **Key Aspects of LLMOps:**\n",
            "    * **Data Management:**\n",
            "        * LLMs require vast amounts of high-quality text data for training.\n",
            "        * LLMOps involves managing and curating this data, ensuring its accuracy, consistency, and relevance to the LLM's intended tasks.\n",
            "    * **Model Training:**\n",
            "        * Training LLMs is computationally intensive and can take weeks or months.\n",
            "        * LLMOps provides tools and techniques for optimizing the training process, managing resources, and monitoring progress.\n",
            "    * **Deployment and Scaling:**\n",
            "        * LLMs are often deployed in production environments to handle large volumes of requests and maintain high performance.\n",
            "        * LLMOps helps ensure efficient deployment, appropriate scaling, and seamless integration with other systems.\n",
            "    * **Monitoring and Maintenance:**\n",
            "        * LLMs require ongoing monitoring to detect and address operational issues.\n",
            "        * LLMOps provides tools and techniques for monitoring model performance, identifying anomalies, and performing necessary maintenance tasks.\n",
            "    * **Governance and Compliance:**\n",
            "        * LLMs can raise ethical, legal, and regulatory concerns due to their potential impact on society.\n",
            "        * LLMOps includes practices and procedures for ensuring responsible and ethical development and use of LLMs, in compliance with relevant regulations and standards.\n",
            "\n",
            "* **Benefits of LLMOps:**\n",
            "    * Streamlined development, deployment, and maintenance of LLMs.\n",
            "    * Improved efficiency, reliability, and overall performance of LLMs.\n",
            "    * Responsible and ethical use of LLMs, minimizing risks and maximizing benefits.\n",
            "\n",
            "References: \n",
            "\n",
            "An Introduction to LLMOps: Operationalizing and Managing Large Language ... :\n",
            "https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/an-introduction-to-llmops-operationalizing-and-managing-large/ba-p/3910996\n",
            "What is LLMOps, and how is it different from MLOps? - Pluralsight :\n",
            "https://www.pluralsight.com/resources/blog/data/what-is-llmops\n"
          ]
        }
      ],
      "source": [
        "res = Chatbot('what is llmops?')\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LezEHLjBUW1s"
      },
      "source": [
        "## Stramlit Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFi2F-sjUV93"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "0g1zSV2UUWAb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "retjk\n",
            "\n",
            "kjtkler\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\\n\".join(['retjk', 'kjtkler']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHBQhRFxUWCw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sg4RxwqQUWFO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2EqLF2xUWHo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLdMSsKAUWKJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOiVTZBuUWMh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7cpWRKOUWOz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrLx7GdqUWRR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOoVftobT-tc"
      },
      "source": [
        "## Future improvements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "Wu8oxi48w4RY",
        "outputId": "dfa7ce69-6546-4434-9314-88d0cb91036f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title: Greetings and Salutations\n",
            "\n",
            "* **Formal Greetings:**\n",
            "    * \"Greetings!\" is a formal way to say hello, often used in professional or academic settings.\n",
            "    * \"Hello!\" is a more casual greeting, suitable for most social situations.\n",
            "    * \"Good morning/afternoon/evening\" is a polite way to greet someone at a specific time of day.\n",
            "    * \"How do you do?\" is a formal way to inquire about someone's well-being.\n",
            "\n",
            "* **Informal Greetings:**\n",
            "    * \"Hey!\" or \"Hi!\" are common informal greetings among friends and acquaintances.\n",
            "    * \"What's up?\" or \"Sup?\" are casual ways to ask someone how they are doing.\n",
            "    * \"Yo!\" is a slang greeting, often used among young people.\n",
            "    * \"Peace out!\" or \"Later!\" are informal ways to say goodbye.\n",
            "\n",
            "* **Songs About Saying Hello:**\n",
            "    * \"Hello\" by Lionel Richie is a classic song about the joy of greeting someone you love.\n",
            "    * \"Hello, Goodbye\" by The Beatles is a song about the bittersweet nature of saying hello and goodbye.\n",
            "    * \"Hello, Dolly!\" by Louis Armstrong is a cheerful song about greeting someone special.\n",
            "    * \"Hello, Young Lovers\" by Rodgers and Hammerstein is a song about the excitement of meeting someone new.\n",
            "\n",
            "References: \n",
            "\n",
            "500+ Ways to say hello formally and informally for different situations ... :\n",
            "https://workwizardry.com/ways-to-say-hello/\n",
            "The 75+ Best Songs About Saying Hello, Ranked By Votes :\n",
            "https://www.ranker.com/list/songs-about-saying-hello/ranker-music\n"
          ]
        }
      ],
      "source": [
        "res = Chatbot('hello')\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKYcU7kHUTW1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "zXpglOv7log7",
        "UecIV4etl6do",
        "qOoVftobT-tc"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
